# -*- coding: utf-8 -*-
"""Intelligent Customer Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1seCxs2L0Yx_tIh-GeNC562HJN37690V6
"""

# !pip install torch transformers sentence-transformers faiss-cpu scikit-learn

!pip install torch

!pip install transformers

!pip install faiss-cpu

!pip install scikit-learn

!pip install sentence-transformers

pip install triton

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModelForSeq2SeqLM
from sentence_transformers import SentenceTransformer
from sklearn.metrics import f1_score
from elasticsearch import Elasticsearch
import numpy as np
import uuid
import json
from datetime import datetime

intent_data = [
    # password_reset
    ("I want to reset my password", "password_reset"),
    ("I forgot my password", "password_reset"),
    ("Can't login to my account", "password_reset"),
    ("How do I change my password?", "password_reset"),
    ("Reset my password please", "password_reset"),

    # payment_issue
    ("My payment failed", "payment_issue"),
    ("Payment did not go through", "payment_issue"),
    ("I was charged twice", "payment_issue"),
    ("My card was declined", "payment_issue"),
    ("Can't make payment", "payment_issue"),

    # complaint
    ("I am very unhappy with the service", "complaint"),
    ("This is unacceptable", "complaint"),
    ("I want to complain about my order", "complaint"),
    ("The service was terrible", "complaint"),
    ("I am frustrated with your support", "complaint"),

    # gratitude
    ("Thank you so much", "gratitude"),
    ("Thanks for your help", "gratitude"),
    ("I really appreciate it", "gratitude"),
    ("Thanks a lot", "gratitude"),
    ("Much appreciated", "gratitude"),

    # order_status
    ("Where is my order?", "order_status"),
    ("Track my order", "order_status"),
    ("I want to know my order status", "order_status"),
    ("My delivery hasn't arrived", "order_status"),
    ("Has my order shipped?", "order_status"),
]

# Create label mappings
intent_labels = sorted(list(set(x[1] for x in intent_data)))
label2id = {label: i for i, label in enumerate(intent_labels)}
id2label = {i: label for label, i in label2id.items()}

texts = [x[0] for x in intent_data]
labels = [label2id[x[1]] for x in intent_data]

print("Intent Labels:", intent_labels)
print("Number of training samples:", len(texts))

model_name = "bert-base-uncased"
intent_tokenizer = AutoTokenizer.from_pretrained(model_name)
intent_model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=len(intent_labels)
)

encoded = intent_tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
label_tensor = torch.tensor(labels)

print("BERT loaded successfully")

optimizer = torch.optim.AdamW(intent_model.parameters(), lr=2e-5)
intent_model.train()

for epoch in range(10):  # increase epochs for better convergence
    total_loss = 0
    for text, label in zip(texts, labels):
        inputs = intent_tokenizer(text, return_tensors="pt", padding=True, truncation=True)
        label_tensor = torch.tensor([label])

        outputs = intent_model(**inputs, labels=label_tensor)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        total_loss += loss.item()

    print(f"Epoch {epoch+1} | Average Loss: {total_loss/len(texts):.4f}")

intent_model.eval()
with torch.no_grad():
    logits = intent_model(**encoded).logits

predictions = torch.argmax(logits, dim=1).numpy()
f1 = f1_score(labels, predictions, average="weighted")

print("Intent Detection F1 Score:", round(f1 * 100, 2), "%")

sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="cardiffnlp/twitter-xlm-roberta-base-sentiment"
)

print(sentiment_pipeline("Estoy muy decepcionado con el servicio"))

knowledge_base = [
    "To reset your password, go to settings and click 'Forgot Password'.",
    "Payment failures may occur due to insufficient balance or bank restrictions.",
    "You can track your order status from the My Orders section in your account.",
]

embedder = SentenceTransformer("all-MiniLM-L6-v2")
kb_embeddings = embedder.encode(knowledge_base)

faiss_index = faiss.IndexFlatL2(kb_embeddings.shape[1])
faiss_index.add(np.array(kb_embeddings))

print("FAISS knowledge base ready")

def retrieve_context(query):
    q_embedding = embedder.encode([query])
    _, idx = faiss_index.search(np.array(q_embedding), 1)
    return knowledge_base[idx[0][0]]

llm_name = "google/flan-t5-small"
llm_tokenizer = AutoTokenizer.from_pretrained(llm_name)
llm_model = AutoModelForSeq2SeqLM.from_pretrained(llm_name)

print("Local LLM loaded")

# Load strong LLM
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

llm_model_name = "google/flan-t5-base"
llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)
llm_model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)

def generate_response(user_text):
    # ---------- INTENT DETECTION ----------
    tokens = intent_tokenizer(user_text, return_tensors="pt")
    with torch.no_grad():
        intent_logits = intent_model(**tokens).logits
    intent = id2label[int(torch.argmax(intent_logits))]

    # ---------- SENTIMENT DETECTION ----------
    sentiment = sentiment_pipeline(user_text)[0]['label']

    # ---------- KNOWLEDGE RETRIEVAL ----------
    context = retrieve_context(user_text)

    # ---------- STRONG PROMPT WITH EXAMPLES ----------
    prompt = f"""
You are a friendly and professional customer support assistant.
You answer both customer support questions and casual conversation naturally.
Do NOT repeat instructions, only respond naturally.

User Message: "{user_text}"
Detected Intent: {intent}
Detected Sentiment: {sentiment}
Relevant Knowledge: {context}

Examples of responses:
- "how are you?" -> "Hi! I'm doing great, thanks for asking ðŸ˜Š How can I assist you today?"
- "thank you" -> "You're welcome! Happy to help ðŸ˜Š"
- "I can't log in" -> "I understand your frustration ðŸ’™ To reset your password, go to settings and click 'Forgot Password'."

Now, reply to the user message in a polite, human-like, empathetic way.
"""

    # ---------- GENERATE RESPONSE ----------
    inputs = llm_tokenizer(prompt, return_tensors="pt", truncation=True)
    outputs = llm_model.generate(**inputs, max_length=150)
    response_text = llm_tokenizer.decode(outputs[0], skip_special_tokens=True)

    return response_text

import json
from datetime import datetime
import uuid

def push_to_crm(user_text, bot_response):
    record = {
        "id": str(uuid.uuid4()),
        "query": user_text,
        "response": bot_response,
        "status": "Resolved",
        "timestamp": str(datetime.now())
    }

    # Save to local JSON file
    with open("local_crm.json", "a") as f:
        f.write(json.dumps(record) + "\n")

    print("Conversation saved to local CRM âœ…")

# Test the chatbot with a single example
user_input = "how are you?"
bot_reply = generate_response(user_input)

print("\nBOT RESPONSE:\n", bot_reply)

# Save to CRM
push_to_crm(user_input, bot_reply)

print("\n--- Intelligent Customer Support Bot ---")
print("Bot: Hello ðŸ‘‹ I'm here to help you. Type 'exit' to quit.\n")

while True:
    user_message = input("Customer: ").strip()

    if user_message.lower() in ["exit", "quit", "bye"]:
        print("Bot: Thank you for contacting support. Take care! ðŸ‘‹")
        break

    # Generate bot response
    bot_message = generate_response(user_message)

    # Show response
    print("\nBot:", bot_message, "\n")

    # Save conversation to local CRM
    push_to_crm(user_message, bot_message)

